#!/usr/bin/env python3
"""
RecBole AutoML - RecVAE Hyperparameter Optimization with Ray Tune

í¬ì†Œì„± 99.9% ë°ì´í„°ì…‹ì— ëŒ€í•œ RecVAE í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
- í‰ê°€ ì§€í‘œ: Recall@5
- AutoML: Ray Tune (ASHA Scheduler + Optuna TPE)
- ë””ë°”ì´ìŠ¤: CUDA â†’ MPS â†’ CPU ìë™ ì„ íƒ
- ëª¨ë¸: RecVAE (Collaborative Filtering with Recurrent Variational Autoencoders)
- íŠ¹ì§•: Composite Prior, ì ì‘í˜• Î², êµëŒ€ í•™ìŠµ
"""

import os
import sys
import warnings
import pandas as pd
import numpy as np
import time
from datetime import datetime
from pathlib import Path
import torch

# RecBole imports
from recbole.config import Config
from recbole.data import create_dataset, data_preparation
from recbole.utils import init_seed, get_model, get_trainer
from recbole.utils.case_study import full_sort_topk

# Ray Tune imports (ìµœì‹  API)
from ray import tune
from ray.train import RunConfig
from ray.tune.schedulers import ASHAScheduler
from ray.tune.search.optuna import OptunaSearch

# Ray Tune ë²„ê·¸ ìš°íšŒ: Monkey Patch
import ray.tune.experimental.output as tune_output
import ray.train._internal.storage as train_storage

# verbose íƒ€ì… ë²„ê·¸ ìˆ˜ì •
original_get_air_verbosity = tune_output.get_air_verbosity
def patched_get_air_verbosity(verbose):
    if isinstance(verbose, str):
        return 1  # ë¬¸ìì—´ì´ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
    return original_get_air_verbosity(verbose)
tune_output.get_air_verbosity = patched_get_air_verbosity

# StorageContext __init__ íƒ€ì… ë²„ê·¸ ìˆ˜ì •
original_storage_init = train_storage.StorageContext.__init__
def patched_storage_init(self, *args, **kwargs):
    # sync_configê°€ ë¬¸ìì—´ì´ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´
    if 'sync_config' in kwargs and isinstance(kwargs['sync_config'], str):
        from ray.train import SyncConfig
        kwargs['sync_config'] = SyncConfig()
    return original_storage_init(self, *args, **kwargs)
train_storage.StorageContext.__init__ = patched_storage_init

warnings.filterwarnings('ignore')

print("=" * 60)
print("RecBole AutoML with Ray Tune - RecVAE")
print("=" * 60)
print("âœ… ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ\n")

# ============================================================
# 1. ë””ë°”ì´ìŠ¤ ìë™ ì„ íƒ
# ============================================================
print("=" * 60)
print("1. ë””ë°”ì´ìŠ¤ ì„ íƒ")
print("=" * 60)

if torch.cuda.is_available():
    device = 'cuda'
    print(f"ğŸš€ ë””ë°”ì´ìŠ¤: CUDA ({torch.cuda.get_device_name(0)})")
elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    device = 'mps'
    print("ğŸ ë””ë°”ì´ìŠ¤: MPS (Apple Silicon)")
else:
    device = 'cpu'
    print("ğŸ’» ë””ë°”ì´ìŠ¤: CPU")

print(f"PyTorch version: {torch.__version__}\n")

# ============================================================
# 2. Ray ì´ˆê¸°í™”
# ============================================================
print("=" * 60)
print("2. Ray ì´ˆê¸°í™”")
print("=" * 60)

import ray

if ray.is_initialized():
    ray.shutdown()
    print("ğŸ”„ ê¸°ì¡´ Ray ì¸ìŠ¤í„´ìŠ¤ ì¢…ë£Œ")

# ì‹œìŠ¤í…œ CPU ì½”ì–´ ìˆ˜ ìë™ ê°ì§€
total_cpus = os.cpu_count() or 4

# ë””ë°”ì´ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤ í• ë‹¹ ì „ëµ
if device == 'cuda':
    # CUDA: CPU/GPU ê²½í•© ë°©ì§€ ìœ„í•´ ì½”ì–´ ìˆ˜ ì œí•œ
    num_cpus = total_cpus // 2  # ì ˆë°˜ë§Œ ì‚¬ìš© (ì—´ ê´€ë¦¬)
    num_gpus = 1
    print(f"ğŸ® CUDA ëª¨ë“œ: CPU {num_cpus}/{total_cpus}ì½”ì–´, GPU 1ê°œ í• ë‹¹")
elif device == 'mps':
    # MPS: í†µí•© ë©”ëª¨ë¦¬ë¡œ ì „ì²´ CPU ì‚¬ìš© ê°€ëŠ¥
    num_cpus = total_cpus
    num_gpus = 0  # MPSëŠ” PyTorch device='mps'ë¡œ ìë™ ì²˜ë¦¬
    print(f"ğŸ MPS ëª¨ë“œ: CPU {num_cpus}ì½”ì–´ í• ë‹¹ (GPU ìë™ ì‚¬ìš©)")
else:
    # CPU only
    num_cpus = total_cpus
    num_gpus = 0
    print(f"ğŸ’» CPU ëª¨ë“œ: {num_cpus}ì½”ì–´ í• ë‹¹")

ray.init(
    ignore_reinit_error=True,
    include_dashboard=False,
    num_cpus=num_cpus,
    num_gpus=num_gpus,
    _temp_dir=None,
    _metrics_export_port=None,
    configure_logging=False,
)

print("âœ… Ray ì´ˆê¸°í™” ì™„ë£Œ")
print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ë¦¬ì†ŒìŠ¤: {ray.available_resources()}\n")

# ============================================================
# 3. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬
# ============================================================
print("=" * 60)
print("3. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬")
print("=" * 60)

start_time = time.time()

# ë°ì´í„° ë¡œë“œ
train_file = 'dataset/apply_train.csv'
df = pd.read_csv(train_file)

# BOM ë¬¸ì ì œê±°
df.columns = [col.replace('\ufeff', '') for col in df.columns]

print(f"âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
print(f"   Total interactions: {len(df):,}")
print(f"   Unique users: {df['resume_seq'].nunique():,}")
print(f"   Unique items: {df['recruitment_seq'].nunique():,}")
print(f"   Sparsity: {1 - len(df) / (df['resume_seq'].nunique() * df['recruitment_seq'].nunique()):.4%}")

# RecBole í˜•ì‹ìœ¼ë¡œ ë³€í™˜
df_recbole = pd.DataFrame({
    'user_id:token': df['resume_seq'],
    'item_id:token': df['recruitment_seq'],
    'rating:float': 1.0
})

# RecBole ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ ìƒì„±
dataset_dir = 'dataset/kaggle_recsys'
os.makedirs(dataset_dir, exist_ok=True)

# .inter íŒŒì¼ë¡œ ì €ì¥
inter_file = os.path.join(dataset_dir, 'kaggle_recsys.inter')
df_recbole.to_csv(inter_file, sep='\t', index=False)

print(f"\nâœ… RecBole ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
print(f"   íŒŒì¼: {inter_file}")
print(f"   í˜•ì‹: Tab-separated (.inter)")
print(f"   ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ\n")

# ============================================================
# 4. Ray Tune ì„¤ì •
# ============================================================
print("=" * 60)
print("4. Ray Tune ì„¤ì •")
print("=" * 60)

MODEL_NAME = 'RecVAE'

# ì ˆëŒ€ ê²½ë¡œë¡œ ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (Ray Tune ë³‘ë ¬ ì‹¤í–‰ ì‹œ í•„ìš”)
DATASET_PATH = str(Path(__file__).parent / 'dataset')

# ë””ë°”ì´ìŠ¤ë³„ ë°°ì¹˜ í¬ê¸° ì„¤ì •
if device == 'cuda':
    # CUDA: GPU ë©”ëª¨ë¦¬ ê²½í•© ë°©ì§€ ìœ„í•´ ë°°ì¹˜ í¬ê¸° ì¶•ì†Œ
    train_batch_size = 1024
    eval_batch_size = 2048
    print(f"ğŸ® CUDA ë°°ì¹˜ í¬ê¸°: train={train_batch_size}, eval={eval_batch_size}")
elif device == 'mps':
    # MPS: í†µí•© ë©”ëª¨ë¦¬ë¡œ í° ë°°ì¹˜ í¬ê¸° ì‚¬ìš© ê°€ëŠ¥
    train_batch_size = 2048
    eval_batch_size = 4096
    print(f"ğŸ MPS ë°°ì¹˜ í¬ê¸°: train={train_batch_size}, eval={eval_batch_size}")
else:
    # CPU: ë©”ëª¨ë¦¬ ì—¬ìœ  ìˆìŒ
    train_batch_size = 2048
    eval_batch_size = 4096
    print(f"ğŸ’» CPU ë°°ì¹˜ í¬ê¸°: train={train_batch_size}, eval={eval_batch_size}")

base_config = {
    'data_path': DATASET_PATH,
    'dataset': 'kaggle_recsys',
    'USER_ID_FIELD': 'user_id',
    'ITEM_ID_FIELD': 'item_id',
    'RATING_FIELD': 'rating',
    'load_col': {'inter': ['user_id', 'item_id', 'rating']},
    'train_neg_sample_args': None,  # í•„ìˆ˜! RecVAEëŠ” non-sampling ëª¨ë¸
    'eval_args': {
        'split': {'RS': [0.8, 0.1, 0.1]},
        'order': 'RO',
        'mode': 'full',
        'group_by': 'user'
    },
    'metrics': ['Recall', 'NDCG', 'MRR'],
    'topk': [5, 10, 20],
    'valid_metric': 'Recall@5',
    'device': device,
    'epochs': 100,
    'stopping_step': 10,
    'train_batch_size': train_batch_size,
    'eval_batch_size': eval_batch_size,
    'seed': 2024,
    'reproducibility': True,
    'show_progress': False,
}

# í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ (RecBole ë¬¸ì„œ + RecVAE ë…¼ë¬¸ ê¸°ë°˜)
# ì¶œì²˜: Shenbin et al., "RecVAE: A New Variational Autoencoder for Top-N Recommendations", WSDM 2020
search_space = {
    'hidden_dimension': tune.choice([512, 600]),           # ì˜¤í† ì¸ì½”ë” ì€ë‹‰ì¸µ, ê¸°ë³¸: 600
    'latent_dimension': tune.choice([128, 200, 256]),      # ì ì¬ ê³µê°„ ì°¨ì›, ê¸°ë³¸: 200
    'dropout_prob': tune.uniform(0.3, 0.7),                # ë“œë¡­ì•„ì›ƒ í™•ë¥ , ê¸°ë³¸: 0.5
    'gamma': tune.loguniform(0.001, 0.01),                 # ì ì‘í˜• Î² ê³„ì‚°ìš©, ê¸°ë³¸: 0.005
    'n_enc_epochs': tune.choice([1, 3]),                   # ì¸ì½”ë” í•™ìŠµ ë°˜ë³µ, ê¸°ë³¸: 3
    'learning_rate': tune.loguniform(1e-4, 1e-2),
}

print(f"âœ… ê¸°ë³¸ ì„¤ì • ì™„ë£Œ")
print(f"   ëª¨ë¸: {MODEL_NAME}")
print(f"   íƒ€ê²Ÿ ë©”íŠ¸ë¦­: Recall@5")
print(f"   ë””ë°”ì´ìŠ¤: {device}")
print(f"\nğŸ” í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„ (RecBole ë¬¸ì„œ + ë…¼ë¬¸ ê¸°ë°˜):")
print(f"   hidden_dimension: [512, 600] (ê¸°ë³¸: 600)")
print(f"   latent_dimension: [128, 200, 256] (ê¸°ë³¸: 200)")
print(f"   dropout_prob: [0.3, 0.7] (ê¸°ë³¸: 0.5)")
print(f"   gamma: [0.001, 0.01] (ì ì‘í˜• Î², ê¸°ë³¸: 0.005)")
print(f"   n_enc_epochs: [1, 3] (ì¸ì½”ë” í•™ìŠµ ë°˜ë³µ, ê¸°ë³¸: 3)")
print(f"   learning_rate: [1e-4, 1e-2] (log-uniform)")
print(f"\nğŸ’¡ RecVAE íŠ¹ì§•: Composite Prior, ì ì‘í˜• Î², êµëŒ€ í•™ìŠµ\n")

# ============================================================
# 5. Trainable í•¨ìˆ˜ ì •ì˜
# ============================================================
print("=" * 60)
print("5. Trainable í•¨ìˆ˜ ì •ì˜")
print("=" * 60)

def train_recbole(config_params):
    """Ray Tune trainable í•¨ìˆ˜ - RecBole RecVAE í•™ìŠµ"""
    from ray import train

    config_dict = base_config.copy()
    config_dict.update({
        'model': MODEL_NAME,
        'hidden_dimension': int(config_params['hidden_dimension']),
        'latent_dimension': int(config_params['latent_dimension']),
        'dropout_prob': config_params['dropout_prob'],
        'gamma': config_params['gamma'],
        'n_enc_epochs': int(config_params['n_enc_epochs']),
        'learning_rate': config_params['learning_rate'],
    })

    try:
        config = Config(model=MODEL_NAME, config_dict=config_dict)
        init_seed(config['seed'], config['reproducibility'])

        dataset = create_dataset(config)
        train_data, valid_data, test_data = data_preparation(config, dataset)

        model = get_model(config['model'])(config, train_data.dataset).to(config['device'])
        trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)

        best_valid_score, best_valid_result = trainer.fit(
            train_data, valid_data, verbose=False, show_progress=False
        )

        recall_5 = best_valid_result['recall@5']
        ndcg_5 = best_valid_result['ndcg@5']
        recall_10 = best_valid_result['recall@10']

        train.report({
            'recall@5': recall_5,
            'ndcg@5': ndcg_5,
            'recall@10': recall_10,
        })

    except Exception as e:
        print(f"âŒ Trial ì‹¤íŒ¨: {str(e)}")
        train.report({
            'recall@5': 0.0,
            'ndcg@5': 0.0,
            'recall@10': 0.0,
        })

print("âœ… Trainable í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n")

# ============================================================
# 6. Ray Tune AutoML ì‹¤í–‰
# ============================================================
print("=" * 60)
print("6. Ray Tune í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œì‘")
print("=" * 60)

start_time = time.time()

# ASHA Scheduler ì„¤ì •
scheduler = ASHAScheduler(
    metric='recall@5',
    mode='max',
    max_t=100,
    grace_period=10,
    reduction_factor=2,
)

# Optuna Search
search_alg = OptunaSearch(
    metric='recall@5',
    mode='max',
)

# Ray Tune ì €ì¥ ê²½ë¡œ
ray_results_path = str(Path('./ray_results').resolve())
print(f"ğŸ“ Ray Tune ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {ray_results_path}")

# ë””ë°”ì´ìŠ¤ë³„ Trial ë¦¬ì†ŒìŠ¤ í• ë‹¹
if device == 'cuda':
    # CUDA: GPU ë©”ëª¨ë¦¬ ê²½í•© ë°©ì§€ ìœ„í•´ ë™ì‹œ ì‹¤í–‰ ì œí•œ
    resources_per_trial = {"cpu": 4, "gpu": 0.5}
    max_concurrent_trials = 2
    print(f"\nğŸ® CUDA Trial ì„¤ì •:")
    print(f"   Trialë‹¹ ë¦¬ì†ŒìŠ¤: CPU 4ì½”ì–´, GPU 0.5ê°œ")
    print(f"   ìµœëŒ€ ë™ì‹œ ì‹¤í–‰: {max_concurrent_trials}ê°œ")
    print(f"   â†’ GPU ë©”ëª¨ë¦¬ ê²½í•© ë°©ì§€, CPU ì—´ ê´€ë¦¬")
elif device == 'mps':
    # MPS: í†µí•© ë©”ëª¨ë¦¬ë¡œ ì œí•œ ë¶ˆí•„ìš”
    resources_per_trial = {"cpu": 2}
    max_concurrent_trials = None  # Rayê°€ ìë™ ê²°ì •
    print(f"\nğŸ MPS Trial ì„¤ì •:")
    print(f"   Trialë‹¹ ë¦¬ì†ŒìŠ¤: CPU 2ì½”ì–´")
    print(f"   ìµœëŒ€ ë™ì‹œ ì‹¤í–‰: ì œí•œ ì—†ìŒ (ìë™)")
    print(f"   â†’ í†µí•© ë©”ëª¨ë¦¬ë¡œ ë³‘ë ¬ ì‹¤í–‰ ìµœì í™”")
else:
    # CPU only
    resources_per_trial = {"cpu": 2}
    max_concurrent_trials = None
    print(f"\nğŸ’» CPU Trial ì„¤ì •:")
    print(f"   Trialë‹¹ ë¦¬ì†ŒìŠ¤: CPU 2ì½”ì–´")
    print(f"   ìµœëŒ€ ë™ì‹œ ì‹¤í–‰: ì œí•œ ì—†ìŒ (ìë™)")

# Ray Tune ì‹¤í–‰
tuner = tune.Tuner(
    tune.with_resources(train_recbole, resources=resources_per_trial),
    param_space=search_space,
    tune_config=tune.TuneConfig(
        scheduler=scheduler,
        search_alg=search_alg,
        num_samples=30,  # RecVAE íƒìƒ‰ ê³µê°„ì— ë§ê²Œ ì„¤ì •
        max_concurrent_trials=max_concurrent_trials,
    ),
    run_config=RunConfig(
        name='recbole_recvae_automl',
        storage_path=ray_results_path,
    ),
)

print("\nğŸš€ ìµœì í™” ì‹œì‘...\n")
results = tuner.fit()

print("\n" + "=" * 60)
print("âœ… Ray Tune ìµœì í™” ì™„ë£Œ")
print(f"   ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
print("=" * 60 + "\n")

# ============================================================
# 7. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ
# ============================================================
print("=" * 60)
print("7. ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° ì¶”ì¶œ")
print("=" * 60)

best_result = results.get_best_result(metric='recall@5', mode='max')
best_config = best_result.config
best_metrics = best_result.metrics

print("\nğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
print(f"   hidden_dimension: {int(best_config['hidden_dimension'])}")
print(f"   latent_dimension: {int(best_config['latent_dimension'])}")
print(f"   dropout_prob: {best_config['dropout_prob']:.4f}")
print(f"   gamma: {best_config['gamma']:.6f}")
print(f"   n_enc_epochs: {int(best_config['n_enc_epochs'])}")
print(f"   learning_rate: {best_config['learning_rate']:.6f}")

print(f"\nğŸ¯ ìµœê³  ê²€ì¦ ì„±ëŠ¥:")
print(f"   Recall@5: {best_metrics['recall@5']:.4f}")
print(f"   NDCG@5: {best_metrics['ndcg@5']:.4f}")
print(f"   Recall@10: {best_metrics['recall@10']:.4f}")

# ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„° JSON íŒŒì¼ë¡œ ì €ì¥ (ì¬í˜„ì„± í™•ë³´)
import json
t_params = pd.Timestamp.now()
params_output_dir = f"outputs/{t_params.year}-{t_params.month:02d}-{t_params.day:02d}"
os.makedirs(params_output_dir, exist_ok=True)
params_filename = f"{params_output_dir}/best_hyperparams_recvae_{t_params.year}{t_params.month:02d}{t_params.day:02d}{t_params.hour:02d}{t_params.minute:02d}{t_params.second:02d}.json"

best_params_to_save = {
    'hyperparameters': {
        'hidden_dimension': int(best_config['hidden_dimension']),
        'latent_dimension': int(best_config['latent_dimension']),
        'dropout_prob': float(best_config['dropout_prob']),
        'gamma': float(best_config['gamma']),
        'n_enc_epochs': int(best_config['n_enc_epochs']),
        'learning_rate': float(best_config['learning_rate'])
    },
    'validation_metrics': {
        'recall@5': float(best_metrics['recall@5']),
        'ndcg@5': float(best_metrics['ndcg@5']),
        'recall@10': float(best_metrics['recall@10'])
    },
    'timestamp': t_params.strftime('%Y-%m-%d %H:%M:%S'),
    'model': MODEL_NAME,
    'device': device,
    'num_trials': len(results.get_dataframe())
}

with open(params_filename, 'w') as f:
    json.dump(best_params_to_save, f, indent=2)

print(f"\nğŸ’¾ ìµœì  íŒŒë¼ë¯¸í„° ì €ì¥ ì™„ë£Œ: {params_filename}\n")

# ============================================================
# 8. ìµœì  ëª¨ë¸ë¡œ ìµœì¢… í•™ìŠµ
# ============================================================
print("=" * 60)
print("8. ìµœì  ëª¨ë¸ë¡œ ìµœì¢… í•™ìŠµ")
print("=" * 60)

start_time = time.time()

final_config_dict = base_config.copy()
final_config_dict.update({
    'model': MODEL_NAME,
    'hidden_dimension': int(best_config['hidden_dimension']),
    'latent_dimension': int(best_config['latent_dimension']),
    'dropout_prob': best_config['dropout_prob'],
    'gamma': best_config['gamma'],
    'n_enc_epochs': int(best_config['n_enc_epochs']),
    'learning_rate': best_config['learning_rate'],
    'show_progress': True,
})

config = Config(model=MODEL_NAME, config_dict=final_config_dict)
init_seed(config['seed'], config['reproducibility'])

dataset = create_dataset(config)
train_data, valid_data, test_data = data_preparation(config, dataset)

model = get_model(config['model'])(config, train_data.dataset).to(config['device'])
trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)

best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)
test_result = trainer.evaluate(test_data)

print("\nâœ… ìµœì¢… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ")
print(f"   ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
print(f"\nğŸ“Š ê²€ì¦ ì„±ëŠ¥:")
print(f"   Recall@5:  {best_valid_result['recall@5']:.4f}")
print(f"   NDCG@5:    {best_valid_result['ndcg@5']:.4f}")
print(f"   Recall@10: {best_valid_result['recall@10']:.4f}")
print(f"\nğŸ“Š í…ŒìŠ¤íŠ¸ ì„±ëŠ¥:")
print(f"   Recall@5:  {test_result['recall@5']:.4f}")
print(f"   NDCG@5:    {test_result['ndcg@5']:.4f}")
print(f"   Recall@10: {test_result['recall@10']:.4f}\n")

# ============================================================
# 9. ì „ì²´ ì‚¬ìš©ì ì¶”ì²œ ìƒì„±
# ============================================================
print("=" * 60)
print("9. ì „ì²´ ì‚¬ìš©ì ì¶”ì²œ ìƒì„±")
print("=" * 60)

start_time = time.time()

all_users = dataset.inter_feat['user_id'].unique()
all_recommendations = {}

topk = 5

model.eval()
with torch.no_grad():
    for i, user_id in enumerate(all_users):
        user_external = dataset.id2token('user_id', user_id.item())

        # full_sort_topk()ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¶”ì²œ ìƒì„± (ë‚´ë¶€ ID ì „ë‹¬)
        topk_scores, topk_indices = full_sort_topk(
            [user_id.item()],  # ë‚´ë¶€ ID (ì •ìˆ˜) ì „ë‹¬
            model,
            test_data,
            k=topk,
            device=config['device']
        )

        # ì¶”ì²œ ì•„ì´í…œ ì™¸ë¶€ IDë¡œ ë³€í™˜
        topk_items_internal = topk_indices[0].cpu().tolist()
        items_external = [dataset.id2token('item_id', int(item)) for item in topk_items_internal]
        all_recommendations[user_external] = items_external

        if (i + 1) % 1000 == 0:
            print(f"   ì§„í–‰: {i + 1}/{len(all_users)} ì‚¬ìš©ì ì²˜ë¦¬ ì™„ë£Œ")

print(f"\nâœ… ì¶”ì²œ ìƒì„± ì™„ë£Œ")
print(f"   ì´ ì‚¬ìš©ì ìˆ˜: {len(all_recommendations):,}")
print(f"   ì‚¬ìš©ìë‹¹ ì¶”ì²œ ìˆ˜: {topk}")
print(f"   ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ\n")

# ============================================================
# 10. ì œì¶œ íŒŒì¼ ìƒì„±
# ============================================================
print("=" * 60)
print("10. ì œì¶œ íŒŒì¼ ìƒì„±")
print("=" * 60)

start_time = time.time()

result = []
for user_id, recs in all_recommendations.items():
    for item_id in recs:
        result.append((user_id, item_id))

submission = pd.DataFrame(result, columns=['resume_seq', 'recruitment_seq'])

print(f"âœ… ì œì¶œ ë°ì´í„° ë³€í™˜ ì™„ë£Œ")
print(f"   ì´ í–‰ ìˆ˜: {len(submission):,}")
print(f"   ì˜ˆìƒ ì¶”ì²œ ìˆ˜/ì‚¬ìš©ì: {len(submission) / len(all_recommendations):.2f}")

t = pd.Timestamp.now()
output_dir = f"outputs/{t.year}-{t.month:02d}-{t.day:02d}"
os.makedirs(output_dir, exist_ok=True)
filename = f"{output_dir}/submit_{MODEL_NAME}_RayTune_{t.year}{t.month:02d}{t.day:02d}{t.hour:02d}{t.minute:02d}{t.second:02d}.csv"

submission.to_csv(filename, index=False)

print(f"\n" + "=" * 60)
print(f"âœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
print("=" * 60)
print(f"íŒŒì¼ëª…: {filename}")
print(f"ê²€ì¦ Recall@5: {best_valid_score:.4f}")
print(f"í…ŒìŠ¤íŠ¸ Recall@5: {test_result['recall@5']:.4f}")
print(f"ì†Œìš” ì‹œê°„: {time.time() - start_time:.2f}ì´ˆ")
print("=" * 60)

# ============================================================
# 11. ê²°ê³¼ ìš”ì•½
# ============================================================
print("\n" + "=" * 60)
print("Ray Tune AutoML ìµœì í™” ê²°ê³¼ ìš”ì•½ - RecVAE")
print("=" * 60)

results_df = results.get_dataframe()

print(f"\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
print(f"   ì‚¬ìš©ì ìˆ˜: {df['resume_seq'].nunique():,}")
print(f"   ì•„ì´í…œ ìˆ˜: {df['recruitment_seq'].nunique():,}")
print(f"   ìƒí˜¸ì‘ìš© ìˆ˜: {len(df):,}")
print(f"   í¬ì†Œì„±: {1 - len(df) / (df['resume_seq'].nunique() * df['recruitment_seq'].nunique()):.4%}")

print(f"\nğŸ¤– AutoML ì •ë³´:")
print(f"   ëª¨ë¸: {MODEL_NAME}")
print(f"   ë””ë°”ì´ìŠ¤: {device}")
print(f"   AutoML ë°©ì‹: Ray Tune (ASHA + Optuna TPE)")
print(f"   ì´ ì‹œë„ íšŸìˆ˜: {len(results_df)}")
print(f"   ì™„ë£Œëœ trial: {len(results_df[results_df['recall@5'] > 0])}")

print(f"\nğŸ† ìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
print(f"   hidden_dimension: {int(best_config['hidden_dimension'])}")
print(f"   latent_dimension: {int(best_config['latent_dimension'])}")
print(f"   dropout_prob: {best_config['dropout_prob']:.4f}")
print(f"   gamma: {best_config['gamma']:.6f}")
print(f"   n_enc_epochs: {int(best_config['n_enc_epochs'])}")
print(f"   learning_rate: {best_config['learning_rate']:.6f}")

print(f"\nğŸ“ˆ ìµœì¢… ì„±ëŠ¥:")
print(f"   ê²€ì¦ Recall@5: {best_valid_result['recall@5']:.4f}")
print(f"   í…ŒìŠ¤íŠ¸ Recall@5: {test_result['recall@5']:.4f}")
print(f"   ê²€ì¦ NDCG@5: {best_valid_result['ndcg@5']:.4f}")
print(f"   í…ŒìŠ¤íŠ¸ NDCG@5: {test_result['ndcg@5']:.4f}")

print(f"\nğŸ’¾ ì¶œë ¥ íŒŒì¼:")
print(f"   ì œì¶œ íŒŒì¼: {filename}")
print(f"   ìµœì  íŒŒë¼ë¯¸í„°: {params_filename}")
print(f"   Ray Tune ê²°ê³¼: {ray_results_path}/recbole_recvae_automl/")

print("\nğŸ“Š ìƒìœ„ 5ê°œ Trial ê²°ê³¼:")
top5 = results_df.nlargest(5, 'recall@5')[['config/hidden_dimension', 'config/latent_dimension',
                                              'config/dropout_prob', 'config/gamma',
                                              'config/n_enc_epochs', 'config/learning_rate',
                                              'recall@5', 'ndcg@5']]
print(top5.to_string(index=False))

print("\n" + "=" * 60)
print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
print("=" * 60)

# Ray ì¢…ë£Œ
ray.shutdown()
print("\nâœ… Ray ì¢…ë£Œ ì™„ë£Œ")
