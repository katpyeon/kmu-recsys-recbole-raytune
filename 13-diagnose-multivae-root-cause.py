#!/usr/bin/env python3
"""
MultiVAE Root Cause Analysis

3ê°€ì§€ ê°€ì„¤ ê²€ì¦:
1. ë°ì´í„° ë¶„í•  ë¬¸ì œ (Test setì´ representativeí•˜ì§€ ì•ŠìŒ?)
2. MultiVAE ì‹¬ê°í•œ Overfitting (10ê°œ ì•„ì´í…œë§Œ ì¶”ì²œ)
3. í‰ê°€ ë°©ì‹ ì°¨ì´ (Metric ê³„ì‚° ë°©ë²• ì°¨ì´?)
"""

import os
import pandas as pd
import numpy as np
from pathlib import Path
from collections import Counter
from recbole.config import Config
from recbole.data import create_dataset, data_preparation
from recbole.utils import init_seed

print("=" * 80)
print("MultiVAE Root Cause Analysis")
print("=" * 80)
print()

# ============================================================
# ë°ì´í„° ì¤€ë¹„
# ============================================================
train_file = 'dataset/comp_train.csv'
df = pd.read_csv(train_file)
df.columns = [col.replace('\ufeff', '') for col in df.columns]

df_recbole = pd.DataFrame({
    'user_id:token': df['user_id'],
    'item_id:token': df['item_id'],
    'rating:float': 1.0
})

dataset_dir = 'dataset/kaggle_recsys'
os.makedirs(dataset_dir, exist_ok=True)
inter_file = os.path.join(dataset_dir, 'kaggle_recsys.inter')
df_recbole.to_csv(inter_file, sep='\t', index=False)

# RecBole ì„¤ì •
DATASET_PATH = str(Path(__file__).parent / 'dataset')
config_dict = {
    'data_path': DATASET_PATH,
    'dataset': 'kaggle_recsys',
    'USER_ID_FIELD': 'user_id',
    'ITEM_ID_FIELD': 'item_id',
    'RATING_FIELD': 'rating',
    'load_col': {'inter': ['user_id', 'item_id', 'rating']},
    'eval_args': {
        'split': {'RS': [0.8, 0.1, 0.1]},
        'order': 'RO',
        'mode': 'full',
        'group_by': 'user'
    },
    'seed': 2024,
}

config = Config(model='BPR', config_dict=config_dict)
init_seed(config['seed'], config['reproducibility'])
dataset = create_dataset(config)
train_data, valid_data, test_data = data_preparation(config, dataset)

print(f"âœ… ë°ì´í„°ì…‹ ì¤€ë¹„")
print(f"   ì „ì²´: {len(df):,}ê°œ interactions")
print(f"   Train: {len(train_data.dataset):,}ê°œ")
print(f"   Valid: {len(valid_data.dataset):,}ê°œ")
print(f"   Test: {len(test_data.dataset):,}ê°œ")
print()

# ============================================================
# ê°€ì„¤ 1: ë°ì´í„° ë¶„í•  ë¬¸ì œ
# ============================================================
print("=" * 80)
print("ê°€ì„¤ 1: ë°ì´í„° ë¶„í•  ë¬¸ì œ ë¶„ì„")
print("=" * 80)
print()

# ì „ì²´ ë°ì´í„° í†µê³„
total_users = df['user_id'].nunique()
total_items = df['item_id'].nunique()
total_interactions = len(df)

print(f"ğŸ“Š ì „ì²´ ë°ì´í„° í†µê³„:")
print(f"   ì‚¬ìš©ì: {total_users:,}ëª…")
print(f"   ì•„ì´í…œ: {total_items:,}ê°œ")
print(f"   Interactions: {total_interactions:,}ê°œ")
print(f"   í‰ê·  interaction/user: {total_interactions/total_users:.2f}")
print()

# Train/Valid/Test ë¶„í•  í†µê³„
train_users = train_data.dataset.inter_feat['user_id'].unique()
valid_users = valid_data.dataset.inter_feat['user_id'].unique()
test_users = test_data.dataset.inter_feat['user_id'].unique()

train_items = train_data.dataset.inter_feat['item_id'].unique()
valid_items = valid_data.dataset.inter_feat['item_id'].unique()
test_items = test_data.dataset.inter_feat['item_id'].unique()

print(f"ğŸ“Š ë¶„í• ë³„ í†µê³„:")
print(f"   Train: {len(train_users):,}ëª…, {len(train_items):,}ê°œ ì•„ì´í…œ")
print(f"   Valid: {len(valid_users):,}ëª…, {len(valid_items):,}ê°œ ì•„ì´í…œ")
print(f"   Test:  {len(test_users):,}ëª…, {len(test_items):,}ê°œ ì•„ì´í…œ")
print()

# Test setì˜ representativeì„± ê²€ì¦
# Testì—ë§Œ ìˆëŠ” ì•„ì´í…œ (Cold-start items)
test_items_external = set([dataset.id2token('item_id', iid.item()) for iid in test_items])
train_items_external = set([dataset.id2token('item_id', iid.item()) for iid in train_items])
cold_start_items = test_items_external - train_items_external

print(f"ğŸ” Test Set Representativeì„±:")
print(f"   Testì—ë§Œ ìˆëŠ” ì•„ì´í…œ (cold-start): {len(cold_start_items):,}ê°œ ({len(cold_start_items)/len(test_items_external)*100:.1f}%)")
print()

if len(cold_start_items) > 0:
    print(f"âš ï¸  ê²½ê³ : Testì— {len(cold_start_items)}ê°œ cold-start ì•„ì´í…œ ì¡´ì¬!")
    print(f"   ì´ëŠ” ëª¨ë¸ì´ ì ˆëŒ€ ì¶”ì²œí•  ìˆ˜ ì—†ëŠ” ì•„ì´í…œì…ë‹ˆë‹¤.")
    print()

# ============================================================
# ê°€ì„¤ 2: MultiVAE Severe Overfitting ë¶„ì„
# ============================================================
print("=" * 80)
print("ê°€ì„¤ 2: MultiVAE Severe Overfitting ë¶„ì„")
print("=" * 80)
print()

# MultiVAE ì œì¶œ íŒŒì¼ ë¶„ì„
multivae_file = 'outputs/2025-11-22/submit_MultiVAE_RayTune_20251122142530.csv'
multivae_df = pd.read_csv(multivae_file)

# ì „ì²´ ì¶”ì²œëœ ì•„ì´í…œ ë¶„ì„
all_recommended_items = []
for items_str in multivae_df['item_ids']:
    all_recommended_items.extend(items_str.split())

item_counter = Counter(all_recommended_items)
unique_items = len(item_counter)
total_recommendations = len(all_recommended_items)

print(f"ğŸ“Š MultiVAE ì¶”ì²œ í†µê³„:")
print(f"   ì´ ì¶”ì²œ ìˆ˜: {total_recommendations:,}ê°œ")
print(f"   ê³ ìœ  ì•„ì´í…œ ìˆ˜: {unique_items:,}ê°œ")
print(f"   ì»¤ë²„ë¦¬ì§€: {unique_items/total_items*100:.2f}% (ì „ì²´ ì•„ì´í…œ ëŒ€ë¹„)")
print()

# Top 20 ê°€ì¥ ë§ì´ ì¶”ì²œëœ ì•„ì´í…œ
print(f"ğŸ“Š ê°€ì¥ ë§ì´ ì¶”ì²œëœ Top 20 ì•„ì´í…œ:")
top_20 = item_counter.most_common(20)
top_20_count = sum(count for _, count in top_20)
for i, (item_id, count) in enumerate(top_20, 1):
    pct = count / total_recommendations * 100
    print(f"   {i:2d}. {item_id}: {count:,}íšŒ ({pct:.1f}%)")

print()
print(f"ğŸ” Top 20 ì•„ì´í…œ ì§‘ì¤‘ë„:")
print(f"   Top 20ì´ ì „ì²´ ì¶”ì²œì˜ {top_20_count/total_recommendations*100:.1f}% ì°¨ì§€")
print()

# ì‚¬ìš©ìë‹¹ ì¶”ì²œ ë‹¤ì–‘ì„±
user_diversity = []
for items_str in multivae_df['item_ids']:
    items = items_str.split()
    user_diversity.append(len(set(items)))

print(f"ğŸ“Š ì‚¬ìš©ìë‹¹ ì¶”ì²œ ë‹¤ì–‘ì„±:")
print(f"   í‰ê· : {np.mean(user_diversity):.2f}ê°œ ê³ ìœ  ì•„ì´í…œ (ìµœëŒ€ 5ê°œ)")
print(f"   ì¤‘ì•™ê°’: {np.median(user_diversity):.0f}ê°œ")
print(f"   ìµœì†Œ: {np.min(user_diversity)}ê°œ, ìµœëŒ€: {np.max(user_diversity)}ê°œ")
print()

# ì „ì²´ ë°ì´í„°ì˜ ì•„ì´í…œ ë¹ˆë„ì™€ ë¹„êµ
train_item_freq = df.groupby('item_id').size().sort_values(ascending=False)
top_20_popular = train_item_freq.head(20).index.tolist()

print(f"ğŸ” MultiVAE ì¶”ì²œ vs ì „ì²´ ë°ì´í„° ì¸ê¸°ë„:")
multivae_top_items = [item_id for item_id, _ in item_counter.most_common(20)]
overlap = len(set(multivae_top_items) & set(top_20_popular))
print(f"   MultiVAE Top 20ê³¼ ì‹¤ì œ Top 20 ê²¹ì¹¨: {overlap}/20ê°œ")
print(f"   â†’ MultiVAEëŠ” {'ì¸ê¸° ì•„ì´í…œë§Œ' if overlap >= 15 else 'ë‹¤ì–‘í•œ ì•„ì´í…œì„'} ì¶”ì²œ")
print()

# ============================================================
# ê°€ì„¤ 3: í‰ê°€ ë°©ì‹ ì°¨ì´
# ============================================================
print("=" * 80)
print("ê°€ì„¤ 3: í‰ê°€ ë°©ì‹ ì°¨ì´ ë¶„ì„")
print("=" * 80)
print()

# Test set ì •ë‹µ ì¶”ì¶œ
test_interactions = {}
for uid in test_data.dataset.inter_feat['user_id'].unique():
    user_external = dataset.id2token('user_id', uid.item())
    user_test_indices = (test_data.dataset.inter_feat['user_id'] == uid).nonzero(as_tuple=True)[0]
    test_items_internal = test_data.dataset.inter_feat['item_id'][user_test_indices]
    test_items_external = [dataset.id2token('item_id', iid.item()) for iid in test_items_internal]
    test_interactions[user_external] = set(test_items_external)

# MultiVAE ì¶”ì²œ íŒŒì‹±
recommendations = {}
for _, row in multivae_df.iterrows():
    user_external = row['user_id']
    items_external = row['item_ids'].split()
    recommendations[user_external] = items_external

# Recall@5, NDCG@5 ê³„ì‚° (ìš°ë¦¬ ë°©ì‹)
recall_at_5 = []
ndcg_at_5 = []
hit_count_dist = []

for user_id, true_items in test_interactions.items():
    if user_id not in recommendations:
        recall_at_5.append(0.0)
        ndcg_at_5.append(0.0)
        hit_count_dist.append(0)
        continue

    pred_items = recommendations[user_id][:5]

    # Recall@5
    hits = len(set(pred_items) & true_items)
    recall = hits / min(len(true_items), 5) if len(true_items) > 0 else 0.0
    recall_at_5.append(recall)
    hit_count_dist.append(hits)

    # NDCG@5
    dcg = 0.0
    idcg = sum([1.0 / np.log2(i + 2) for i in range(min(len(true_items), 5))])
    for i, item in enumerate(pred_items):
        if item in true_items:
            dcg += 1.0 / np.log2(i + 2)
    ndcg = dcg / idcg if idcg > 0 else 0.0
    ndcg_at_5.append(ndcg)

avg_recall = np.mean(recall_at_5)
avg_ndcg = np.mean(ndcg_at_5)

print(f"ğŸ“Š ìš°ë¦¬ í‰ê°€ ë°©ì‹ (Test Set):")
print(f"   Recall@5: {avg_recall:.4f}")
print(f"   NDCG@5: {avg_ndcg:.4f}")
print()

# Hit count ë¶„í¬
hit_counter = Counter(hit_count_dist)
print(f"ğŸ“Š Hit Count ë¶„í¬ (Top 5 ì¶”ì²œ ì¤‘ ëª‡ ê°œê°€ ì •ë‹µ?):")
for hits in sorted(hit_counter.keys()):
    count = hit_counter[hits]
    pct = count / len(test_interactions) * 100
    print(f"   {hits}ê°œ íˆíŠ¸: {count:,}ëª… ({pct:.1f}%)")
print()

# ============================================================
# ì¢…í•© ë¶„ì„
# ============================================================
print("=" * 80)
print("ì¢…í•© ë¶„ì„")
print("=" * 80)
print()

print(f"ğŸ” ê°€ì„¤ ê²€ì¦ ê²°ê³¼:")
print()

print(f"1ï¸âƒ£  ë°ì´í„° ë¶„í•  ë¬¸ì œ:")
if len(cold_start_items) > 10:
    print(f"   âš ï¸  CRITICAL: Testì— {len(cold_start_items)}ê°œ cold-start ì•„ì´í…œ ì¡´ì¬")
    print(f"   â†’ ì´ëŠ” ì„±ëŠ¥ì„ ì¸ìœ„ì ìœ¼ë¡œ ë‚®ì¶œ ìˆ˜ ìˆìŒ")
else:
    print(f"   âœ… Test setì€ representativeí•¨ (cold-start ì•„ì´í…œ {len(cold_start_items)}ê°œ)")
print()

print(f"2ï¸âƒ£  MultiVAE Severe Overfitting:")
if unique_items < 50:
    print(f"   âŒ CRITICAL: ë‹¨ {unique_items}ê°œ ì•„ì´í…œë§Œ ì¶”ì²œ")
    print(f"   â†’ ì‹¬ê°í•œ overfitting / popularity bias")
    print(f"   â†’ ì»¤ë²„ë¦¬ì§€: {unique_items/total_items*100:.2f}% (ëª©í‘œ: >10%)")
else:
    print(f"   âœ… ì¶”ì²œ ë‹¤ì–‘ì„±: {unique_items}ê°œ ì•„ì´í…œ")
print()

print(f"3ï¸âƒ£  í‰ê°€ ë°©ì‹ ì°¨ì´:")
print(f"   ìš°ë¦¬ Test Recall@5: {avg_recall:.4f}")
print(f"   Public LB Recall@5: 0.197")
print(f"   ê²©ì°¨: {abs(avg_recall - 0.197):.4f} (2.4ë°°)")
print()
if abs(avg_recall - 0.197) > 0.05:
    print(f"   âŒ CRITICAL: 2.4ë°° ê²©ì°¨ëŠ” ë¹„ì •ìƒì ")
    print(f"   â†’ í‰ê°€ ë°ì´í„°ê°€ ë‹¤ë¥´ê±°ë‚˜ metric ê³„ì‚°ì´ ë‹¤ë¦„")
    print(f"   â†’ Public LBëŠ” ë‹¤ë¥¸ test setì„ ì‚¬ìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ì¶”ì •")
else:
    print(f"   âœ… ê²©ì°¨ê°€ í•©ë¦¬ì  ë²”ìœ„")
print()

# ============================================================
# ìµœì¢… ì§„ë‹¨
# ============================================================
print("=" * 80)
print("ìµœì¢… ì§„ë‹¨ ë° ê¶Œì¥ì‚¬í•­")
print("=" * 80)
print()

print(f"ğŸ¯ í•µì‹¬ ë¬¸ì œ:")
print()

if unique_items < 50:
    print(f"1. MultiVAE ì‹¬ê°í•œ Overfitting (ë‹¨ {unique_items}ê°œ ì•„ì´í…œë§Œ ì¶”ì²œ)")
    print(f"   ì›ì¸:")
    print(f"   - Dropout ë„ˆë¬´ ë†’ìŒ (0.519)")
    print(f"   - Learning rate ë„ˆë¬´ ë‚®ìŒ (5.34e-05)")
    print(f"   - Anneal cap ë„ˆë¬´ ë†’ìŒ (0.4)")
    print()
    print(f"   ê¶Œì¥ ì¡°ì¹˜:")
    print(f"   - Dropout: 0.3~0.4ë¡œ ë‚®ì¶”ê¸°")
    print(f"   - Learning rate: 1e-4 ~ 1e-3ë¡œ ë†’ì´ê¸°")
    print(f"   - Anneal cap: 0.1~0.2ë¡œ ë‚®ì¶”ê¸°")
    print(f"   - Regularization ì™„í™”í•˜ì—¬ ëª¨ë¸ capacity í™•ë³´")
    print()

if abs(avg_recall - 0.197) > 0.05:
    print(f"2. í‰ê°€ ë°ì´í„° ë¶ˆì¼ì¹˜ (Test={avg_recall:.4f} vs Public LB=0.197)")
    print(f"   ì›ì¸:")
    print(f"   - Public LBëŠ” ë‹¤ë¥¸ test set ì‚¬ìš©")
    print(f"   - ìš°ë¦¬ëŠ” 80/10/10 splitì˜ 10% testë§Œ ì‚¬ìš©")
    print(f"   - Public LBëŠ” ë³„ë„ì˜ hidden test set ì‚¬ìš©")
    print()
    print(f"   ê¶Œì¥ ì¡°ì¹˜:")
    print(f"   - ì „ì²´ ë°ì´í„°ë¡œ ì¬í•™ìŠµ (No split)")
    print(f"   - Validationì€ cross-validation ì‚¬ìš©")
    print(f"   - Public LB ì ìˆ˜ë¥¼ ì‹ ë¢°í•˜ê³  ìµœì í™”")
    print()

if len(cold_start_items) > 10:
    print(f"3. Cold-start ì•„ì´í…œ ë¬¸ì œ ({len(cold_start_items)}ê°œ)")
    print(f"   ê¶Œì¥ ì¡°ì¹˜:")
    print(f"   - Data split ë°©ì‹ ë³€ê²½ (item-based split ëŒ€ì‹  time-based)")
    print()

print("=" * 80)
print("âœ… ë¶„ì„ ì™„ë£Œ")
print("=" * 80)
