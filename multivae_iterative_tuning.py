#!/usr/bin/env python3
"""
RecBole MultiVAE - Iterative Hyperparameter Tuning with Automatic Stopping

ì „ëµ:
- ì§§ì€ ì‹¤í—˜ ë°˜ë³µ (12â†’10â†’8 trials)
- ì„±ëŠ¥ ì¶”ì  ë° ìë™ ì¤‘ë‹¨
- ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ì œì¶œ íŒŒì¼ ìƒì„±

ì¤‘ë‹¨ ì¡°ê±´:
- 2íšŒ ì—°ì† ì„±ëŠ¥ í•˜ë½
- 3íšŒ ì—°ì† 0.3% ë¯¸ë§Œ ê°œì„ 
- ìµœëŒ€ 5íšŒ ë°˜ë³µ
"""

import os
import sys
import warnings
import pandas as pd
import numpy as np
import time
import json
from datetime import datetime
from pathlib import Path
import torch

# RecBole imports
from recbole.config import Config
from recbole.data import create_dataset, data_preparation
from recbole.utils import init_seed, get_model, get_trainer
from recbole.utils.case_study import full_sort_topk

# Ray Tune imports
from ray import tune
from ray.train import RunConfig
from ray.tune.schedulers import ASHAScheduler
from ray.tune.search.optuna import OptunaSearch

# Ray Tune ë²„ê·¸ ìš°íšŒ
import ray.tune.experimental.output as tune_output
import ray.train._internal.storage as train_storage

original_get_air_verbosity = tune_output.get_air_verbosity
def patched_get_air_verbosity(verbose):
    if isinstance(verbose, str):
        return 1
    return original_get_air_verbosity(verbose)
tune_output.get_air_verbosity = patched_get_air_verbosity

original_storage_init = train_storage.StorageContext.__init__
def patched_storage_init(self, *args, **kwargs):
    if 'sync_config' in kwargs and isinstance(kwargs['sync_config'], str):
        from ray.train import SyncConfig
        kwargs['sync_config'] = SyncConfig()
    return original_storage_init(self, *args, **kwargs)
train_storage.StorageContext.__init__ = patched_storage_init

original_torch_load = torch.load
def patched_torch_load(*args, **kwargs):
    if 'weights_only' not in kwargs:
        kwargs['weights_only'] = False
    return original_torch_load(*args, **kwargs)
torch.load = patched_torch_load

warnings.filterwarnings('ignore')

print("=" * 80)
print("MultiVAE ë°˜ë³µ íŠœë‹ - ìë™ ì¤‘ë‹¨ ë° ìµœì í™”")
print("=" * 80)
print()

# ============================================================
# ë””ë°”ì´ìŠ¤ ì„ íƒ
# ============================================================
if torch.cuda.is_available():
    device = 'cuda'
    print(f"ğŸš€ ë””ë°”ì´ìŠ¤: CUDA ({torch.cuda.get_device_name(0)})")
elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
    device = 'mps'
    print("ğŸ ë””ë°”ì´ìŠ¤: MPS")
else:
    device = 'cpu'
    print("ğŸ’» ë””ë°”ì´ìŠ¤: CPU")

# ============================================================
# Ray ì´ˆê¸°í™”
# ============================================================
import ray

if ray.is_initialized():
    ray.shutdown()

total_cpus = os.cpu_count() or 4

if device == 'cuda':
    num_cpus = total_cpus
    num_gpus = 1
elif device == 'mps':
    num_cpus = total_cpus
    num_gpus = 0
else:
    num_cpus = total_cpus
    num_gpus = 0

ray.init(
    ignore_reinit_error=True,
    include_dashboard=False,
    num_cpus=num_cpus,
    num_gpus=num_gpus,
    _temp_dir=None,
    _metrics_export_port=None,
    configure_logging=False,
)

print(f"âœ… Ray ì´ˆê¸°í™” ì™„ë£Œ\n")

# ============================================================
# ë°ì´í„° ë¡œë”©
# ============================================================
print("=" * 80)
print("ë°ì´í„° ë¡œë”©")
print("=" * 80)

train_file = 'dataset/comp_train.csv'
df = pd.read_csv(train_file)
df.columns = [col.replace('\ufeff', '') for col in df.columns]

print(f"âœ… ë°ì´í„° ë¡œë“œ: {len(df):,}ê°œ ìƒí˜¸ì‘ìš©")
print(f"   ì‚¬ìš©ì: {df['user_id'].nunique():,}, ì•„ì´í…œ: {df['item_id'].nunique():,}")
print(f"   í¬ì†Œì„±: {1 - len(df) / (df['user_id'].nunique() * df['item_id'].nunique()):.4%}\n")

# RecBole í˜•ì‹ ë³€í™˜
df_recbole = pd.DataFrame({
    'user_id:token': df['user_id'],
    'item_id:token': df['item_id'],
    'rating:float': 1.0
})

dataset_dir = 'dataset/kaggle_recsys'
os.makedirs(dataset_dir, exist_ok=True)
inter_file = os.path.join(dataset_dir, 'kaggle_recsys.inter')
df_recbole.to_csv(inter_file, sep='\t', index=False)

# ============================================================
# ê¸°ë³¸ ì„¤ì •
# ============================================================
MODEL_NAME = 'MultiVAE'
DATASET_PATH = str(Path(__file__).parent / 'dataset')

if device == 'cuda':
    train_batch_size = 4096
    eval_batch_size = 102400
elif device == 'mps':
    train_batch_size = 2048
    eval_batch_size = 4096
else:
    train_batch_size = 2048
    eval_batch_size = 4096

base_config = {
    'data_path': DATASET_PATH,
    'dataset': 'kaggle_recsys',
    'USER_ID_FIELD': 'user_id',
    'ITEM_ID_FIELD': 'item_id',
    'RATING_FIELD': 'rating',
    'load_col': {'inter': ['user_id', 'item_id', 'rating']},
    'train_neg_sample_args': None,
    'eval_args': {
        'split': {'RS': [0.8, 0.1, 0.1]},
        'order': 'RO',
        'mode': 'full',
        'group_by': 'user'
    },
    'metrics': ['Recall', 'NDCG', 'MRR'],
    'topk': [5, 10, 20],
    'valid_metric': 'Recall@5',
    'device': device,
    'epochs': 100,
    'stopping_step': 10,
    'train_batch_size': train_batch_size,
    'eval_batch_size': eval_batch_size,
    'seed': 2024,
    'reproducibility': False,
    'show_progress': False,
    'worker': 4,
}

# ============================================================
# Trainable í•¨ìˆ˜
# ============================================================
def train_recbole(config_params):
    from ray import train

    config_dict = base_config.copy()
    config_dict.update({
        'model': MODEL_NAME,
        'latent_dimension': int(config_params['latent_dimension']),
        'mlp_hidden_size': config_params['mlp_hidden_size'],
        'dropout_prob': config_params['dropout_prob'],
        'anneal_cap': config_params['anneal_cap'],
        'learning_rate': config_params['learning_rate'],
    })

    try:
        config = Config(model=MODEL_NAME, config_dict=config_dict)
        init_seed(config['seed'], config['reproducibility'])

        dataset = create_dataset(config)
        train_data, valid_data, test_data = data_preparation(config, dataset)

        model = get_model(config['model'])(config, train_data.dataset).to(config['device'])
        trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)

        best_valid_score, best_valid_result = trainer.fit(
            train_data, valid_data, verbose=False, show_progress=False
        )

        train.report({
            'recall@5': best_valid_result['recall@5'],
            'ndcg@5': best_valid_result['ndcg@5'],
            'recall@10': best_valid_result['recall@10'],
        })
    except Exception as e:
        print(f"âŒ Trial ì‹¤íŒ¨: {str(e)}")
        train.report({'recall@5': 0.0, 'ndcg@5': 0.0, 'recall@10': 0.0})

# ============================================================
# ë°˜ë³µ íƒìƒ‰ ê³µê°„ ì •ì˜ í•¨ìˆ˜
# ============================================================
def get_search_space(iteration, iterations):
    """ë°˜ë³µ ë²ˆí˜¸ì™€ ì´ì „ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ íƒìƒ‰ ê³µê°„ ë°˜í™˜"""

    if iteration == 1:
        # Iteration 1: ìµœì ê°’ ì£¼ë³€ ì„¸ë°€ íƒìƒ‰
        return {
            'latent_dimension': tune.choice([128, 200]),
            'mlp_hidden_size': tune.choice([[600], [512]]),
            'dropout_prob': tune.uniform(0.28, 0.65),
            'anneal_cap': tune.choice([0.1, 0.2, 0.3]),
            'learning_rate': tune.loguniform(3e-4, 1.5e-3),
        }

    # ì´ì „ ìµœê³  ê²°ê³¼ ë¶„ì„
    prev_best = max(iterations, key=lambda x: x['recall@5'])
    prev_config = prev_best['config']
    prev_recall = prev_best['recall@5']

    # Baselineê³¼ ë¹„êµ
    baseline_recall = 0.087
    improvement = prev_recall - baseline_recall

    if improvement > 0.002:  # 0.2% ì´ìƒ ê°œì„ 
        # ê°œì„ ë¨ â†’ ì¶•ì†Œí•˜ì—¬ ì •ë°€ íƒìƒ‰
        best_lr = prev_config['learning_rate']
        best_dropout = prev_config['dropout_prob']

        return {
            'latent_dimension': tune.choice([int(prev_config['latent_dimension'])]),
            'mlp_hidden_size': tune.choice([prev_config['mlp_hidden_size']]),
            'dropout_prob': tune.uniform(max(0.25, best_dropout - 0.1), min(0.7, best_dropout + 0.1)),
            'anneal_cap': tune.choice([prev_config['anneal_cap']]),
            'learning_rate': tune.loguniform(best_lr * 0.7, best_lr * 1.3),
        }
    else:
        # ì •ì²´ â†’ ë‹¤ë¥¸ ë°©í–¥ íƒìƒ‰
        return {
            'latent_dimension': tune.choice([200, 256]),
            'mlp_hidden_size': tune.choice([[600]]),
            'dropout_prob': tune.uniform(0.2, 0.75),
            'anneal_cap': tune.choice([0.2, 0.4, 0.5]),
            'learning_rate': tune.loguniform(3e-4, 2e-3),
        }

# ============================================================
# ì¤‘ë‹¨ ì¡°ê±´ ì²´í¬
# ============================================================
def should_stop(iterations):
    """ì¤‘ë‹¨ ì¡°ê±´ ì²´í¬"""
    if len(iterations) < 2:
        return False

    recalls = [it['recall@5'] for it in iterations]

    # ì¡°ê±´ 1: 2íšŒ ì—°ì† í•˜ë½
    if len(recalls) >= 2:
        if recalls[-1] < recalls[-2] and recalls[-2] < recalls[-3] if len(recalls) >= 3 else False:
            return True

    # ì¡°ê±´ 2: 3íšŒ ì—°ì† 0.3% ë¯¸ë§Œ ê°œì„ 
    if len(recalls) >= 3:
        improvements = [recalls[i] - recalls[i-1] for i in range(-2, 0)]
        if all(imp < 0.003 for imp in improvements):
            return True

    # ì¡°ê±´ 3: ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    if len(iterations) >= 5:
        return True

    return False

def get_stop_reason(iterations):
    """ì¤‘ë‹¨ ì´ìœ  ë°˜í™˜"""
    recalls = [it['recall@5'] for it in iterations]

    if len(iterations) >= 5:
        return "ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜ ë„ë‹¬ (5íšŒ)"

    if len(recalls) >= 2:
        if recalls[-1] < recalls[-2]:
            if len(recalls) >= 3 and recalls[-2] < recalls[-3]:
                return "2íšŒ ì—°ì† ì„±ëŠ¥ í•˜ë½"

    if len(recalls) >= 3:
        improvements = [recalls[i] - recalls[i-1] for i in range(-2, 0)]
        if all(imp < 0.003 for imp in improvements):
            return "3íšŒ ì—°ì† 0.3% ë¯¸ë§Œ ê°œì„  (ì •ì²´)"

    return "ì•Œ ìˆ˜ ì—†ìŒ"

# ============================================================
# ë°˜ë³µ íŠœë‹ ì‹¤í–‰
# ============================================================
print("=" * 80)
print("ë°˜ë³µ íŠœë‹ ì‹œì‘")
print("=" * 80)
print()

iterations = []
baseline_recall = 0.087

ray_results_path = str(Path('./ray_results').resolve())

if device == 'cuda':
    resources_per_trial = {"cpu": 1, "gpu": 0.16}
    max_concurrent_trials = 6
elif device == 'mps':
    resources_per_trial = {"cpu": 2}
    max_concurrent_trials = None
else:
    resources_per_trial = {"cpu": 2}
    max_concurrent_trials = None

for iteration in range(1, 6):
    print("=" * 80)
    print(f"ITERATION {iteration}")
    print("=" * 80)

    # íƒìƒ‰ ê³µê°„ ê²°ì •
    search_space = get_search_space(iteration, iterations)

    # Trial ìˆ˜ ê²°ì •
    if iteration == 1:
        num_trials = 12
    elif iteration == 2:
        num_trials = 10
    else:
        num_trials = 8

    print(f"\nğŸ” íƒìƒ‰ ê³µê°„:")
    for key, value in search_space.items():
        print(f"   {key}: {value}")
    print(f"\nğŸ“Š Trial ìˆ˜: {num_trials}\n")

    # Ray Tune ì‹¤í–‰
    scheduler = ASHAScheduler(
        metric='recall@5',
        mode='max',
        max_t=100,
        grace_period=10,
        reduction_factor=2,
    )

    search_alg = OptunaSearch(
        metric='recall@5',
        mode='max',
    )

    tuner = tune.Tuner(
        tune.with_resources(train_recbole, resources=resources_per_trial),
        param_space=search_space,
        tune_config=tune.TuneConfig(
            scheduler=scheduler,
            search_alg=search_alg,
            num_samples=num_trials,
            max_concurrent_trials=max_concurrent_trials,
        ),
        run_config=RunConfig(
            name=f'recbole_multivae_iter{iteration}',
            storage_path=ray_results_path,
        ),
    )

    start_time = time.time()
    results = tuner.fit()
    elapsed = time.time() - start_time

    # ìµœê³  ê²°ê³¼ ì¶”ì¶œ
    best_result = results.get_best_result(metric='recall@5', mode='max')
    best_config = best_result.config
    best_metrics = best_result.metrics

    recall = best_metrics['recall@5']
    improvement = recall - baseline_recall

    # ê²°ê³¼ ì €ì¥
    iterations.append({
        'iteration': iteration,
        'recall@5': recall,
        'ndcg@5': best_metrics['ndcg@5'],
        'config': best_config,
        'improvement': improvement,
        'elapsed': elapsed,
        'num_trials': num_trials
    })

    # ê²°ê³¼ ì¶œë ¥
    print(f"\n{'=' * 80}")
    print(f"ITERATION {iteration} ì™„ë£Œ")
    print(f"{'=' * 80}")
    print(f"ğŸ¯ Recall@5: {recall:.4f} ({improvement:+.4f} vs baseline)")
    print(f"â±ï¸  ì†Œìš” ì‹œê°„: {elapsed:.1f}ì´ˆ")
    print(f"\nìµœì  í•˜ì´í¼íŒŒë¼ë¯¸í„°:")
    print(f"   learning_rate: {best_config['learning_rate']:.6f}")
    print(f"   dropout_prob: {best_config['dropout_prob']:.4f}")
    print(f"   anneal_cap: {best_config['anneal_cap']:.4f}")
    print(f"   latent_dimension: {int(best_config['latent_dimension'])}")
    print(f"   mlp_hidden_size: {best_config['mlp_hidden_size']}\n")

    # ì¤‘ë‹¨ ì¡°ê±´ ì²´í¬
    if should_stop(iterations):
        print(f"ğŸ›‘ ì¤‘ë‹¨: {get_stop_reason(iterations)}\n")
        break

# ============================================================
# ìµœì¢… ê²°ê³¼ ë° ë¹„êµí‘œ
# ============================================================
print("=" * 80)
print("ë°˜ë³µ íŠœë‹ ìµœì¢… ê²°ê³¼")
print("=" * 80)
print()

# ìµœê³  ì„±ëŠ¥ ì°¾ê¸°
best_iteration = max(iterations, key=lambda x: x['recall@5'])

print(f"âœ… ìµœê³  ì„±ëŠ¥: Iteration {best_iteration['iteration']}")
print(f"   Recall@5: {best_iteration['recall@5']:.4f}")
print(f"   Baseline ëŒ€ë¹„: {best_iteration['improvement']:+.4f} ({best_iteration['improvement']/baseline_recall*100:+.1f}%)\n")

# ë¹„êµí‘œ
print("=" * 80)
print("ì„±ëŠ¥ ë¹„êµí‘œ")
print("=" * 80)
print()
print(f"{'Version':<15} {'Recall@5':<10} {'ê°œì„ ':<10} {'LR':<12} {'Dropout':<10} {'Anneal':<8} {'Trials':<8}")
print("-" * 80)
print(f"{'Baseline':<15} {baseline_recall:<10.4f} {'-':<10} {'0.000517':<12} {'0.302':<10} {'0.2':<8} {'30':<8}")

for it in iterations:
    cfg = it['config']
    print(f"{'Iter ' + str(it['iteration']):<15} {it['recall@5']:<10.4f} "
          f"{it['improvement']:+.4f}    {cfg['learning_rate']:<12.6f} "
          f"{cfg['dropout_prob']:<10.4f} {cfg['anneal_cap']:<8.2f} {it['num_trials']:<8}")

print()

# ============================================================
# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ìµœì¢… í•™ìŠµ ë° ì œì¶œ íŒŒì¼ ìƒì„±
# ============================================================
print("=" * 80)
print("ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë¡œ ìµœì¢… í•™ìŠµ ë° ì œì¶œ íŒŒì¼ ìƒì„±")
print("=" * 80)
print()

best_config = best_iteration['config']

final_config_dict = base_config.copy()
final_config_dict.update({
    'model': MODEL_NAME,
    'latent_dimension': int(best_config['latent_dimension']),
    'mlp_hidden_size': best_config['mlp_hidden_size'],
    'dropout_prob': best_config['dropout_prob'],
    'anneal_cap': best_config['anneal_cap'],
    'learning_rate': best_config['learning_rate'],
    'show_progress': True,
})

config = Config(model=MODEL_NAME, config_dict=final_config_dict)
init_seed(config['seed'], config['reproducibility'])

dataset = create_dataset(config)
train_data, valid_data, test_data = data_preparation(config, dataset)

model = get_model(config['model'])(config, train_data.dataset).to(config['device'])
trainer = get_trainer(config['MODEL_TYPE'], config['model'])(config, model)

best_valid_score, best_valid_result = trainer.fit(train_data, valid_data)
test_result = trainer.evaluate(test_data)

print(f"\nâœ… ìµœì¢… í•™ìŠµ ì™„ë£Œ")
print(f"   ê²€ì¦ Recall@5: {best_valid_result['recall@5']:.4f}")
print(f"   í…ŒìŠ¤íŠ¸ Recall@5: {test_result['recall@5']:.4f}\n")

# ì¶”ì²œ ìƒì„±
print("ì¶”ì²œ ìƒì„± ì¤‘...")
all_users = dataset.inter_feat['user_id'].unique()
all_recommendations = {}

model.eval()
with torch.no_grad():
    for i, user_id in enumerate(all_users):
        user_external = dataset.id2token('user_id', user_id.item())

        topk_scores, topk_indices = full_sort_topk(
            [user_id.item()],
            model,
            test_data,
            k=5,
            device=config['device']
        )

        topk_items_internal = topk_indices[0].cpu().tolist()
        items_external = [dataset.id2token('item_id', int(item)) for item in topk_items_internal]
        all_recommendations[user_external] = items_external

# ì œì¶œ íŒŒì¼ ìƒì„±
result = []
for user_id, recs in all_recommendations.items():
    items_str = ' '.join(recs)
    result.append((user_id, items_str))

submission = pd.DataFrame(result, columns=['user_id', 'item_ids'])

t = pd.Timestamp.now()
output_dir = f"outputs/{t.year}-{t.month:02d}-{t.day:02d}"
os.makedirs(output_dir, exist_ok=True)
filename = f"{output_dir}/submit_MultiVAE_Iterative_Best_{t.year}{t.month:02d}{t.day:02d}{t.hour:02d}{t.minute:02d}{t.second:02d}.csv"

submission.to_csv(filename, index=False)

print(f"\nâœ… ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ!")
print(f"   íŒŒì¼ëª…: {filename}")
print(f"   Recall@5: {test_result['recall@5']:.4f}")

# íŒŒë¼ë¯¸í„° ì €ì¥
params_filename = f"{output_dir}/best_hyperparams_multivae_iterative_{t.year}{t.month:02d}{t.day:02d}{t.hour:02d}{t.minute:02d}{t.second:02d}.json"

params_to_save = {
    'best_iteration': best_iteration['iteration'],
    'hyperparameters': {
        'latent_dimension': int(best_config['latent_dimension']),
        'mlp_hidden_size': best_config['mlp_hidden_size'],
        'dropout_prob': float(best_config['dropout_prob']),
        'anneal_cap': float(best_config['anneal_cap']),
        'learning_rate': float(best_config['learning_rate'])
    },
    'validation_metrics': {
        'recall@5': float(best_valid_result['recall@5']),
        'ndcg@5': float(best_valid_result['ndcg@5']),
    },
    'test_metrics': {
        'recall@5': float(test_result['recall@5']),
        'ndcg@5': float(test_result['ndcg@5']),
    },
    'iterations_summary': [
        {
            'iteration': it['iteration'],
            'recall@5': float(it['recall@5']),
            'improvement': float(it['improvement']),
        }
        for it in iterations
    ],
    'timestamp': t.strftime('%Y-%m-%d %H:%M:%S'),
}

with open(params_filename, 'w') as f:
    json.dump(params_to_save, f, indent=2)

print(f"   íŒŒë¼ë¯¸í„°: {params_filename}")

print("\n" + "=" * 80)
print("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
print("=" * 80)

ray.shutdown()
