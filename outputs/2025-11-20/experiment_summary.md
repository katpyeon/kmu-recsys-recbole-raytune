# RecBole AutoML 실험 결과 보고서
**날짜:** 2025년 11월 20일
**프레임워크:** RecBole + Ray Tune
**디바이스:** MPS (Apple Silicon) / CPU
**데이터셋:** apply_train.csv

---

## 요약

Ray Tune을 활용하여 4개의 추천 모델에 대한 하이퍼파라미터 최적화 실험을 수행했습니다. LightGCN이 **Recall@5 0.0937**, **NDCG@5 0.0604**로 최고 성능을 달성하였으며, 그래프 합성곱 네트워크를 통해 사용자-아이템 상호작용 모델링에서 우수한 성능을 입증했습니다.

---

## 모델 성능 비교

### Recall@5 순위

| 순위 | 모델 | Recall@5 | NDCG@5 | Recall@10 | 실행시간 |
|------|-------|----------|--------|-----------|---------|
| 🥇 1 | **LightGCN** | **0.0937** | **0.0604** | 0.1465 | ~17분 |
| 🥈 2 | EASE | 0.0834 | 0.0547 | 0.1298 | ~27분 |
| 🥉 3 | RecVAE | 0.0826 | 0.0512 | 0.1305 | ~1시간 6분 |
| 4 | MultiVAE | 0.0799 | 0.0515 | 0.1220 | ~1시간 4분 |

### 성능 시각화

```
Recall@5 성능:
LightGCN  ████████████████████ 0.0937
EASE      █████████████████▊   0.0834
RecVAE    █████████████████▌   0.0826
MultiVAE  █████████████████    0.0799

NDCG@5 성능:
LightGCN  ████████████████████ 0.0604
EASE      ██████████████████   0.0547
MultiVAE  █████████████████    0.0515
RecVAE    ████████████████▊    0.0512
```

---

## 상세 모델 결과

### 1. LightGCN (그래프 기반) 🏆
**타임스탬프:** 2025-11-20 20:17:34
**실행시간:** ~17분 (20:05 - 20:17)
**시도 횟수:** 30회
**디바이스:** MPS

#### 최적 하이퍼파라미터
```json
{
  "embedding_size": 256,
  "n_layers": 1,
  "reg_weight": 3.864e-05,
  "learning_rate": 0.001094
}
```

#### 검증 지표
- **Recall@5:** 0.0937 (최고)
- **NDCG@5:** 0.0604 (최고)
- **Recall@10:** 0.1465 (최고)

#### 핵심 인사이트
- 단일 레이어 GCN이 최고 성능 (n_layers=1)
- 큰 임베딩 크기(256)와 최소한의 정규화
- 모든 모델 중 가장 빠른 수렴 속도
- 그래프 구조를 통한 협업 필터링 신호 포착에 최적

---

### 2. EASE (선형 모델) 🥈
**타임스탬프:** 2025-11-20 21:34:07
**실행시간:** ~27분
**시도 횟수:** 10회 (단순한 모델이므로 적게 수행)
**디바이스:** CPU

#### 최적 하이퍼파라미터
```json
{
  "reg_weight": 250.0
}
```

#### 검증 지표
- **Recall@5:** 0.0834 (2위)
- **NDCG@5:** 0.0547 (2위)
- **Recall@10:** 0.1298

#### 핵심 인사이트
- 하이퍼파라미터 1개만 사용하는 가장 단순한 모델
- 단순성에도 불구하고 강력한 성능 (비용 효율적인 베이스라인)
- 강한 정규화(250.0)로 과적합 방지
- 성능과 계산 효율성의 균형이 우수
- GPU/MPS 불필요, CPU 기반 학습 가능

---

### 3. RecVAE (변분 오토인코더) 🥉
**타임스탬프:** 2025-11-20 22:11:04
**실행시간:** ~1시간 6분 (21:07 - 22:11)
**시도 횟수:** 30회
**디바이스:** MPS

#### 최적 하이퍼파라미터
```json
{
  "hidden_dimension": 512,
  "latent_dimension": 200,
  "dropout_prob": 0.5797,
  "gamma": 0.00633,
  "n_enc_epochs": 3,
  "learning_rate": 0.000384
}
```

#### 검증 지표
- **Recall@5:** 0.0826 (3위)
- **NDCG@5:** 0.0512
- **Recall@10:** 0.1305

#### 핵심 인사이트
- 큰 은닉층 차원(512)과 중간 크기 잠재 공간(200)
- 높은 드롭아웃 비율(58%)로 정규화
- 다중 인코더 에폭(3)으로 더 나은 표현 학습
- MultiVAE보다 약간 나은 성능이지만 학습 시간 더 김
- 복잡한 아키텍처로 세심한 튜닝 필요

---

### 4. MultiVAE (변분 오토인코더)
**타임스탬프:** 2025-11-20 21:17:07
**실행시간:** ~1시간 4분 (20:17 - 21:17)
**시도 횟수:** 30회
**디바이스:** MPS

#### 최적 하이퍼파라미터
```json
{
  "latent_dimension": 256,
  "mlp_hidden_size": [512],
  "dropout_prob": 0.5552,
  "anneal_cap": 0.1,
  "learning_rate": 0.000996
}
```

#### 검증 지표
- **Recall@5:** 0.0799 (4위)
- **NDCG@5:** 0.0515
- **Recall@10:** 0.1220

#### 핵심 인사이트
- 큰 잠재 공간(256)과 단일 은닉층(512)
- 중간 수준의 드롭아웃(55.5%) 정규화
- KL 발산을 위한 낮은 어닐링 캡(0.1)
- RecVAE와 유사한 성능이지만 더 단순한 아키텍처
- 성능 대비 긴 학습 시간

---

## 교차 모델 분석

### 성능 vs. 복잡도 트레이드오프

| 모델 | 복잡도 | 성능 | 학습 시간 | 효율성 점수 |
|-------|--------|------|----------|------------|
| LightGCN | 중간 | 높음 (0.0937) | 낮음 (17분) | ⭐⭐⭐⭐⭐ |
| EASE | 매우 낮음 | 중상 (0.0834) | 낮음 (27분) | ⭐⭐⭐⭐⭐ |
| RecVAE | 매우 높음 | 중간 (0.0826) | 높음 (66분) | ⭐⭐⭐ |
| MultiVAE | 높음 | 중간 (0.0799) | 높음 (64분) | ⭐⭐⭐ |

### 주요 발견 사항

1. **그래프 기반 모델의 우세:** LightGCN의 그래프 구조가 VAE 접근법보다 협업 패턴을 더 효과적으로 포착

2. **단순함의 승리:** EASE가 최소한의 복잡도와 GPU 없이도 LightGCN 성능의 89% 달성

3. **VAE 모델의 저조한 성능:** 정교한 아키텍처와 긴 학습 시간에도 불구하고 두 VAE 변형 모두 더 단순한 모델에 뒤처짐

4. **학습 효율성:** LightGCN이 최고의 ROI 제공 - 최단 학습 시간에 최고 성능

5. **정규화 패턴:**
   - LightGCN: 최소 정규화 (3.86e-05)
   - EASE: 강한 정규화 (250.0)
   - VAE들: 드롭아웃 기반 정규화 (~55-58%)

---

## 인사이트 및 개선 방안

### ✅ 잘된 점

1. **LightGCN 아키텍처:** 큰 임베딩(256)을 가진 단일 레이어 GCN이 사용자-아이템 상호작용을 효과적으로 포착
2. **그래프 합성곱:** 그래프 구조 활용이 우수한 협업 필터링 제공
3. **EASE의 단순성:** 강한 정규화를 가진 선형 모델이 효율적인 베이스라인으로 작동
4. **MPS 가속:** Apple Silicon GPU가 신경망 모델 학습을 크게 가속화

### ⚠️ 개선이 필요한 점

1. **VAE 복잡도:** 복잡한 아키텍처가 더 나은 성능으로 이어지지 않음
2. **깊은 네트워크:** 다층 GCN (n_layers > 1)이 단일 레이어보다 성능 저조
3. **학습 시간:** VAE 모델이 LightGCN보다 4배 긴 시간에 열등한 결과

### 🚀 개선 제안

#### 1. 모델 아키텍처
- **LightGCN 변형 모델 집중:** 어텐션 메커니즘 실험 (LightGCN + GAT)
- **앙상블 접근법:** LightGCN 예측과 EASE를 결합하여 잠재적 성능 향상
- **다른 그래프 모델 탐색:** NGCF, UltraGCN 등 비교 연구

#### 2. 하이퍼파라미터 튜닝
- **LightGCN 세밀화:**
  - 임베딩 크기 128-512 범위를 더 조밀하게 테스트
  - 학습률 스케줄링 탐색
  - 다양한 메시지 전달 집계 방식 시도
- **EASE 최적화:**
  - 정규화 값을 200-300 범위에서 미세 조정
  - 더 큰 데이터셋에서 확장성 검증

#### 3. 학습 전략
- **조기 종료:** VAE 학습 시간 단축을 위한 구현
- **워밍업 스케줄링:** 특히 그래프 모델의 초기 학습 안정화
- **배치 크기 튜닝:** 현재 설정이 MPS 디바이스에 최적이 아닐 수 있음

#### 4. 데이터 및 피처
- **피처 엔지니어링:** 시간적 특성, 아이템 메타데이터 통합
- **데이터 증강:** 네거티브 샘플링 전략 추가
- **콜드 스타트 처리:** 신규 사용자/아이템을 위한 하이브리드 접근법 개발

#### 5. 평가
- **추가 지표:** Hit Rate, MRR, 커버리지 지표 포함
- **사용자 세그먼트 분석:** 사용자 활동 수준별 성능 평가
- **A/B 테스팅:** 상위 모델 (LightGCN, EASE) 온라인 평가 배포

#### 6. 프로덕션 고려사항
- **모델 서빙:** 성능을 위한 LightGCN, 빠른 대체재로 EASE
- **추론 지연시간:** 실시간 추천 지연시간 측정 및 최적화
- **모델 업데이트:** 데이터 드리프트 기반 재학습 일정 수립

---

## 기술 사양

### 하드웨어 구성
- **디바이스:** MPS (Apple Silicon M-시리즈 칩)
- **대체:** 비가속 모델용 CPU (EASE)

### 소프트웨어 스택
- **프레임워크:** RecBole (PyTorch 기반)
- **AutoML:** Ray Tune (하이퍼파라미터 최적화)
- **최적화 기법:** 베이지안 최적화 / HyperBand

### 탐색 공간 요약
- **LightGCN:** 4개 하이퍼파라미터, 30회 시도
- **EASE:** 1개 하이퍼파라미터, 10회 시도
- **RecVAE:** 6개 하이퍼파라미터, 30회 시도
- **MultiVAE:** 5개 하이퍼파라미터, 30회 시도

---

## 결론

**LightGCN이 명확한 우승자로 부상**했으며, 최소한의 학습 시간(17분)에 최고의 Recall@5 (0.0937)와 NDCG@5 (0.0604)를 달성했습니다. 그래프 합성곱 접근법은 이분 그래프 구조에서 메시지 전달을 통해 사용자-아이템 상호작용을 효과적으로 모델링합니다.

**EASE는 탁월한 가치를 제공**하며, GPU 요구사항 없이 빠르고 해석 가능한 베이스라인(Recall@5: 0.0834)으로서 리소스 제약 환경이나 실시간 애플리케이션에 적합합니다.

**VAE 모델들(RecVAE, MultiVAE)은 저조한 성능**을 보였으며, 복잡도와 학습 시간 대비 성능이 낮아 이 데이터셋에는 더 단순한 그래프 기반 또는 선형 모델이 더 적합함을 시사합니다.

### 다음 단계
1. 추론 최적화를 통한 LightGCN 프로덕션 배포
2. 현재 베이스라인 대비 온라인 A/B 테스팅 수행
3. LightGCN + EASE 결합 앙상블 방법 탐색
4. 추가 개선을 위한 고급 그래프 모델 (GAT, NGCF) 조사
5. 모델 드리프트 모니터링 및 재학습 트리거 구현

---

**실험 수행:** KMU RecSys Team
**저장소:** kmu-recsys-recbole-raytune
**생성일:** 2025-11-20
